{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a5431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]\n",
      "PySpark: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "import sys, pyspark\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PySpark:\", pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3a618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"TestSpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.range(10)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules, and create the SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookCF_Project\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d539ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- book_author: string (nullable = true)\n",
      " |-- year_of_publication: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- img_s: string (nullable = true)\n",
      " |-- img_m: string (nullable = true)\n",
      " |-- img_l: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "Raw row count: 515339\n"
     ]
    }
   ],
   "source": [
    "# import Book.cvs\n",
    "file_path = \"data/Books.csv\"  \n",
    "df_raw = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# check the schema\n",
    "df_raw.printSchema()\n",
    "\n",
    "# get the number of total rows\n",
    "print(\"Raw row count:\", df_raw.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8e0fa",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "1. Clean `ISBN` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28216c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|isbn_clean|isbn_count|\n",
      "+----------+----------+\n",
      "| 971880107|      2501|\n",
      "| 316666343|      1295|\n",
      "| 385504209|       883|\n",
      "|  60928336|       732|\n",
      "| 312195516|       723|\n",
      "| 044023722|       647|\n",
      "| 142001740|       615|\n",
      "| 067976402|       614|\n",
      "| 671027360|       586|\n",
      "| 446672211|       585|\n",
      "+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "After ISBN cleaning + freq>=2, rows: 101786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# only keep figures\n",
    "df1 = df_raw.withColumn(\n",
    "    \"isbn_clean\",\n",
    "    F.regexp_replace(F.col(\"isbn\"), \"[^0-9]\", \"\")\n",
    ")\n",
    "\n",
    "# drop the blank cells\n",
    "df1 = df1.filter(F.length(F.col(\"isbn_clean\")) > 0)\n",
    "\n",
    "# count non-empty ISBN\n",
    "isbn_counts = df1.groupBy(\"isbn_clean\").agg(F.count(\"*\").alias(\"isbn_count\"))\n",
    "isbn_counts.orderBy(F.col(\"isbn_count\").desc()).show(10)\n",
    "\n",
    "# keep ISBN which appears >= 2 times\n",
    "isbn_keep = isbn_counts.filter(F.col(\"isbn_count\") >= 2).select(\"isbn_clean\")\n",
    "\n",
    "df1 = df1.join(isbn_keep, on=\"isbn_clean\", how=\"inner\")\n",
    "\n",
    "# update\n",
    "df1 = df1.drop(\"isbn\").withColumnRenamed(\"isbn_clean\", \"isbn\")\n",
    "\n",
    "print(\"After ISBN cleaning + freq>=2, rows:\", df1.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a0fd1",
   "metadata": {},
   "source": [
    "2. We selected these columns `user_id`, `isbn`, `rating`, `book_title`, `book_author`, `year_of_poblication`, `publisher`, `Summary`, `Language`, `Category` to analyze and dropped the remaining columns, including demographics (`location`, `age`, `state`, `country`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d1a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- book_author: string (nullable = true)\n",
      " |-- year_of_publication: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the index row\n",
    "df_raw = df_raw.drop(\"_c0\")\n",
    "\n",
    "ratings_raw = df_raw.select(\n",
    "    \"user_id\",\n",
    "    \"isbn\",\n",
    "    \"rating\",\n",
    "    \"book_title\",\n",
    "    \"book_author\",\n",
    "    \"year_of_publication\",\n",
    "    \"publisher\",\n",
    "    \"Summary\",\n",
    "    \"Language\",\n",
    "    \"Category\"\n",
    ")\n",
    "\n",
    "ratings_raw.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1c2b4",
   "metadata": {},
   "source": [
    "3. Clean `rating`:  \n",
    "**Step 5 in the PDF given by prof <- moved earlier to ensure data validity**\n",
    "- string -> float[0,10]\n",
    "- remove invaild ratings\n",
    "- keep the rating 0, but it will be treated as \"no rating\" in the collaborative filtering stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08a671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row number: 515339\n",
      "Row number with valided rating: 101859\n",
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|   0.0|59201|\n",
      "|   1.0|  200|\n",
      "|   2.0|  296|\n",
      "|   3.0|  591|\n",
      "|   4.0|  777|\n",
      "|   5.0| 3732|\n",
      "|   6.0| 3093|\n",
      "|   7.0| 6868|\n",
      "|   8.0|10665|\n",
      "|   9.0| 7935|\n",
      "|  10.0| 8501|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# string -> float[0,10]\n",
    "ratings_num = ratings_raw.withColumn(\n",
    "    \"rating\",\n",
    "    F.col(\"rating\").cast(\"float\")\n",
    ")\n",
    "\n",
    "# remove invaild ratings\n",
    "ratings_valid = ratings_num.filter(\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"rating\") >= 0.0) &\n",
    "    (F.col(\"rating\") <= 10.0)\n",
    ")\n",
    "\n",
    "print(\"Original row number:\", ratings_raw.count())\n",
    "print(\"Row number with valided rating:\", ratings_valid.count())\n",
    "\n",
    "ratings_valid.groupBy(\"rating\").count().orderBy(\"rating\").show(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095b020",
   "metadata": {},
   "source": [
    "4. Count the number of ratings for each user and only retain active users who give >= 5 ratings\n",
    "\n",
    "Users with fewer than 5 ratings are removed because Pearson correlation requires enough observations to be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b541ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|user_id|num_ratings|\n",
      "+-------+-----------+\n",
      "|  11676|        664|\n",
      "|    254|        300|\n",
      "|  35859|        255|\n",
      "|  16795|        222|\n",
      "| 153662|        208|\n",
      "|  76352|        203|\n",
      "| 230522|        202|\n",
      "|  60244|        196|\n",
      "|  55492|        187|\n",
      "| 204864|        184|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Active user number: 3885\n",
      "Total rating number after retaining only active users: 66985\n"
     ]
    }
   ],
   "source": [
    "user_activity = ratings_valid.groupBy(\"user_id\").agg(F.count(\"*\").alias(\"num_ratings\"))\n",
    "\n",
    "user_activity.orderBy(F.col(\"num_ratings\").desc()).show(10)\n",
    "\n",
    "users_active = user_activity.filter(F.col(\"num_ratings\") >= 5)\n",
    "\n",
    "print(\"Active user number:\", users_active.count())\n",
    "\n",
    "ratings_active = ratings_valid.join(\n",
    "    users_active.select(\"user_id\"),\n",
    "    on=\"user_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Total rating number after retaining only active users:\", ratings_active.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f2817",
   "metadata": {},
   "source": [
    "5. Only retain users whose rated books overlap with others by at least one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20116b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with at least one overlapping book: 3885\n",
      "Rows after removing isolated users: 66985\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|user_id|   isbn|rating|  book_title|         book_author|year_of_publication|           publisher|             Summary|Language|Category|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|      8|2005018|   5.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  11400|2005018|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  11676|2005018|   8.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  85526|2005018|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  96054|2005018|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only reamain books rated by 2 or more users \n",
    "book_user_counts = ratings_active.groupBy(\"isbn\") \\\n",
    "    .agg(F.countDistinct(\"user_id\").alias(\"num_users_for_book\"))\n",
    "\n",
    "overlap_books = book_user_counts.filter(F.col(\"num_users_for_book\") >= 2) \\\n",
    "    .select(\"isbn\")\n",
    "\n",
    "# All users related these books\n",
    "ratings_on_overlap_books = ratings_active.join(overlap_books, on=\"isbn\", how=\"inner\")\n",
    "overlap_users = ratings_on_overlap_books.select(\"user_id\").distinct()\n",
    "\n",
    "print(\"Users with at least one overlapping book:\", overlap_users.count())\n",
    "\n",
    "# In the original active rating table, only retain the ratings of overlap_users \n",
    "ratings_overlap_users = ratings_active.join(\n",
    "    overlap_users,\n",
    "    on=\"user_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Rows after removing isolated users:\", ratings_overlap_users.count())\n",
    "\n",
    "ratings_overlap_users.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b91111",
   "metadata": {},
   "source": [
    "6. Filter out books: \n",
    "- Each book must have >= 5 ratings\n",
    "- Remove books with extreme high/low rating given by few people\n",
    "\n",
    "Books with fewer than 5 ratings are removed because they do not provide enough data to compute reliable correlations with other books or users so that the similarity estimates will be more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccce9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books kept after filering: 1272\n",
      "Rows after filtering unpopular / extreme books: 65428\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|   isbn|user_id|rating|  book_title|         book_author|year_of_publication|           publisher|             Summary|Language|Category|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|2005018|      8|   5.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  11400|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  11676|   8.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  85526|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  96054|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_unusual = ratings_overlap_users.groupBy(\"isbn\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_ratings\"),\n",
    "        F.avg(\"rating\").alias(\"avg_rating\")\n",
    "    )\n",
    "\n",
    "books_keep = book_unusual.filter(\n",
    "    (F.col(\"num_ratings\") >= 5) &\n",
    "    ~((F.col(\"avg_rating\") >= 9.5) & (F.col(\"num_ratings\") <= 3)) &\n",
    "    ~((F.col(\"avg_rating\") <= 1.0) & (F.col(\"num_ratings\") <= 3))\n",
    ").select(\"isbn\")\n",
    "\n",
    "print(\"Books kept after filering:\",\n",
    "      books_keep.count())\n",
    "\n",
    "ratings_filtered_books = ratings_overlap_users.join(\n",
    "    books_keep,\n",
    "    on=\"isbn\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Rows after filtering unpopular / extreme books:\",\n",
    "      ratings_filtered_books.count())\n",
    "\n",
    "ratings_filtered_books.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d561",
   "metadata": {},
   "source": [
    "7. Remove duplicate books\n",
    "\n",
    "To remove duplicate books, we group editions by normalized (`title`,`author`) and select a canonical ISBN per group. All ratings for other editions are mapped to this canonical ISBN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2c6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number before merging editions: 65428\n",
      "Row number after merging editions to canonical ISBNs: 65428\n",
      "+----------+-------+------+--------------------------------+-----------+-------------------+---------+-----------------------------------------------------------------+--------+--------+--------------------------------+-----------+----------+----------+\n",
      "|isbn      |user_id|rating|book_title                      |book_author|year_of_publication|publisher|Summary                                                          |Language|Category|title_norm                      |author_norm|isbn_can  |isbn_final|\n",
      "+----------+-------+------+--------------------------------+-----------+-------------------+---------+-----------------------------------------------------------------+--------+--------+--------------------------------+-----------+----------+----------+\n",
      "|038078243X|16721  |0.0   |Miss Zukas and the Raven's Dance|Jo Dereske |1996               |Avon     |Murder victim Stanley Plummer has been cataloging a collection of|NULL    |NULL    |miss zukas and the raven's dance|jo dereske |038078243X|038078243X|\n",
      "|038078243X|30735  |8.0   |Miss Zukas and the Raven's Dance|Jo Dereske |1996               |Avon     |Murder victim Stanley Plummer has been cataloging a collection of|NULL    |NULL    |miss zukas and the raven's dance|jo dereske |038078243X|038078243X|\n",
      "|038078243X|50730  |0.0   |Miss Zukas and the Raven's Dance|Jo Dereske |1996               |Avon     |Murder victim Stanley Plummer has been cataloging a collection of|NULL    |NULL    |miss zukas and the raven's dance|jo dereske |038078243X|038078243X|\n",
      "|038078243X|114868 |0.0   |Miss Zukas and the Raven's Dance|Jo Dereske |1996               |Avon     |Murder victim Stanley Plummer has been cataloging a collection of|NULL    |NULL    |miss zukas and the raven's dance|jo dereske |038078243X|038078243X|\n",
      "|038078243X|136313 |0.0   |Miss Zukas and the Raven's Dance|Jo Dereske |1996               |Avon     |Murder victim Stanley Plummer has been cataloging a collection of|NULL    |NULL    |miss zukas and the raven's dance|jo dereske |038078243X|038078243X|\n",
      "+----------+-------+------+--------------------------------+-----------+-------------------+---------+-----------------------------------------------------------------+--------+--------+--------------------------------+-----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize book_title and book_author\n",
    "ratings_norm = ratings_filtered_books.withColumn(\n",
    "    \"title_norm\",\n",
    "    F.lower(F.regexp_replace(F.col(\"book_title\"), r\"\\s+\", \" \"))\n",
    ").withColumn(\n",
    "    \"author_norm\",\n",
    "    F.lower(F.regexp_replace(F.col(\"book_author\"), r\"\\s+\", \" \"))\n",
    ")\n",
    "\n",
    "# Count the number of ratings for each ISBN within every (title_norm, author_norm, isbn) group.\n",
    "book_isbn_stats = ratings_norm.groupBy(\n",
    "    \"title_norm\", \"author_norm\", \"isbn\"\n",
    ").agg(\n",
    "    F.count(\"*\").alias(\"num_ratings_for_isbn\")\n",
    ")\n",
    "\n",
    "# For each (title_norm, author_norm) group, select the ISBN with the largest number of ratings as the canonical ISBN.\n",
    "w = Window.partitionBy(\"title_norm\", \"author_norm\") \\\n",
    "          .orderBy(F.col(\"num_ratings_for_isbn\").desc(), F.col(\"isbn\"))\n",
    "\n",
    "can_isbn_per_book = book_isbn_stats.withColumn(\n",
    "    \"rank_in_group\",\n",
    "    F.row_number().over(w)\n",
    ").filter(\n",
    "    F.col(\"rank_in_group\") == 1\n",
    ").select(\n",
    "    \"title_norm\", \"author_norm\", F.col(\"isbn\").alias(\"isbn_can\")\n",
    ")\n",
    "\n",
    "# Create mapping table\n",
    "isbn_with_norm = book_isbn_stats.select(\"title_norm\", \"author_norm\", \"isbn\")\n",
    "\n",
    "edition_to_rep = isbn_with_norm.join(\n",
    "    can_isbn_per_book,\n",
    "    on=[\"title_norm\", \"author_norm\"],\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    \"isbn\", \"isbn_can\"\n",
    ")\n",
    "\n",
    "# Replace each edition’s ISBN in the ratings table with its corresponding canonical ISBN\n",
    "ratings_mapped = ratings_norm.join(\n",
    "    edition_to_rep,\n",
    "    on=\"isbn\",\n",
    "    how=\"left\"\n",
    ").withColumn(\n",
    "    \"isbn_final\",\n",
    "    F.coalesce(F.col(\"isbn_can\"), F.col(\"isbn\"))  \n",
    ")\n",
    "\n",
    "# In the ratings table, a single user may have rated multiple editions of the same logical book. \n",
    "# Therefore, we aggregate the data by (user_id, isbn_final) to ensure that each user–book pair has only one rating.\n",
    "ratings_rep_books = ratings_mapped.groupBy(\n",
    "    \"user_id\", \"isbn_final\"\n",
    ").agg(\n",
    "    F.avg(\"rating\").alias(\"rating\"),               \n",
    "    F.count(\"*\").alias(\"num_times\"),               \n",
    "    F.first(\"book_title\").alias(\"book_title\"),\n",
    "    F.first(\"book_author\").alias(\"book_author\"),\n",
    "    F.first(\"year_of_publication\").alias(\"year_of_publication\"),\n",
    "    F.first(\"publisher\").alias(\"publisher\"),\n",
    "    F.first(\"Summary\").alias(\"Summary\"),\n",
    "    F.first(\"Language\").alias(\"Language\"),\n",
    "    F.first(\"Category\").alias(\"Category\")\n",
    ").withColumnRenamed(\n",
    "    \"isbn_final\", \"isbn\"   \n",
    ")\n",
    "\n",
    "print(\"Row number before merging editions:\", ratings_mapped.count())\n",
    "print(\"Row number after merging editions to canonical ISBNs:\", ratings_mapped.count())\n",
    "ratings_mapped.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ccda6",
   "metadata": {},
   "source": [
    "8. Merge duplicates: Only one rating is retained for each user and each book\n",
    "\n",
    "Users may have rated the same book several times, for exemple, rating the same book which has different versions twice.\n",
    "If a user rated the same book twice, keep the highest rating. We keep one copy of book metadata (using `.first()`) and book metadata will be cleaned and reconstructed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05752ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number before deduplication: 65428\n",
      "Row number after deduplication: 65192\n",
      "+-------+---------+------+---------+---------------------------------------------------------------------------------------------+-----------------+-------------------+----------------+----------------------------------------------------------------------+--------+--------+\n",
      "|user_id|isbn     |rating|num_times|book_title                                                                                   |book_author      |year_of_publication|publisher       |Summary                                                               |Language|Category|\n",
      "+-------+---------+------+---------+---------------------------------------------------------------------------------------------+-----------------+-------------------+----------------+----------------------------------------------------------------------+--------+--------+\n",
      "|100009 |385504209|8.0   |1        |The Da Vinci Code                                                                            |Dan Brown        |2003               |Doubleday       |Harvard symbologist Robert Langdon and French cryptologist Sophie     |NULL    |NULL    |\n",
      "|100009 |60502258 |6.0   |1        |The Divine Secrets of the Ya-Ya Sisterhood: A Novel                                          |Rebecca Wells    |2002               |HarperTorch     |SiddaLee has escaped her Louisiana hometown to become a theatrical    |NULL    |NULL    |\n",
      "|100115 |345465083|0.0   |1        |Seabiscuit                                                                                   |LAURA HILLENBRAND|2003               |Ballantine Books|Retraces the journey of Seabiscuit, a horse with crooked legs and a   |NULL    |NULL    |\n",
      "|100115 |786868716|10.0  |1        |The Five People You Meet in Heaven                                                           |Mitch Albom      |2003               |Hyperion        |With a timeless tale, appealing to all, this is a book that readers of|NULL    |NULL    |\n",
      "|100223 |316789089|9.0   |1        |The Pilot's Wife : A Novel Tag: Author of the Weight of Water (Oprah's Book Club (Hardcover))|Anita Shreve     |1999               |Little, Brown   |9                                                                     |9       |9       |\n",
      "+-------+---------+------+---------+---------------------------------------------------------------------------------------------+-----------------+-------------------+----------------+----------------------------------------------------------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_merged = ratings_mapped.groupBy(\n",
    "    \"user_id\", \"isbn_final\"\n",
    ").agg(\n",
    "    F.max(\"rating\").alias(\"rating\"),               \n",
    "    F.count(\"*\").alias(\"num_times\"),               \n",
    "    F.first(\"book_title\").alias(\"book_title\"),\n",
    "    F.first(\"book_author\").alias(\"book_author\"),\n",
    "    F.first(\"year_of_publication\").alias(\"year_of_publication\"),\n",
    "    F.first(\"publisher\").alias(\"publisher\"),\n",
    "    F.first(\"Summary\").alias(\"Summary\"),\n",
    "    F.first(\"Language\").alias(\"Language\"),\n",
    "    F.first(\"Category\").alias(\"Category\")\n",
    ").withColumnRenamed(\n",
    "    \"isbn_final\", \"isbn\"   \n",
    ")\n",
    "\n",
    "print(\"Row number before deduplication:\", ratings_mapped.count())\n",
    "print(\"Row number after deduplication:\", ratings_merged.count())\n",
    "ratings_merged.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2d8c4",
   "metadata": {},
   "source": [
    "9. Split the data into a ratings table and a book metadata table\n",
    "\n",
    "We keep two separate core tables: `ratings_clean`, which stores user–book interactions (`user_id`, `isbn`, `rating`), and\n",
    "`books_clean`, which stores book-level metadata.\n",
    "This separation avoids duplicating metadata for every rating, makes the rating matrix cleaner for collaborative filtering, and allows us to update book information independently from the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff4e928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ratings_clean rows: 65192\n",
      "Final books_clean rows (distinct books): 1218\n"
     ]
    }
   ],
   "source": [
    "ratings_clean = ratings_merged.select(\n",
    "    \"user_id\",\n",
    "    \"isbn\",\n",
    "    \"rating\"\n",
    ")\n",
    "\n",
    "print(\"Final ratings_clean rows:\", ratings_clean.count())\n",
    "\n",
    "books_before_cleaning = ratings_rep_books.select(\n",
    "    \"isbn\",\n",
    "    \"book_title\",\n",
    "    \"book_author\",\n",
    "    \"year_of_publication\",\n",
    "    \"publisher\",\n",
    "    \"Summary\",\n",
    "    \"Language\",\n",
    "    \"Category\"\n",
    ").dropDuplicates([\"isbn\"])\n",
    "\n",
    "print(\"Final books_clean rows (distinct books):\", books_before_cleaning.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31172cb1",
   "metadata": {},
   "source": [
    "10. Clean the book metadate <- Step 10 in the PDF given by prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d77311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final books_clean rows: 1218\n",
      "+----------+-------------------------------------------------------------+----------------+-------------------+------------------------+-------+--------+--------+\n",
      "|isbn      |book_title                                                   |book_author     |year_of_publication|publisher               |Summary|Language|Category|\n",
      "+----------+-------------------------------------------------------------+----------------+-------------------+------------------------+-------+--------+--------+\n",
      "|000649840X|Angelas Ashes                                                |Frank Mccourt   |1994               |Harpercollins Uk        |9      |9       |9       |\n",
      "|006000438X|The Death of Vishnu: A Novel                                 |Manil Suri      |2002               |Perennial               |9      |9       |9       |\n",
      "|006017143X|The Night Listener                                           |Armistead Maupin|2000               |HarperCollins Publishers|9      |9       |9       |\n",
      "|006019491X|Daughter of Fortune : A Novel (Oprah's Book Club (Hardcover))|Isabel Allende  |1999               |HarperCollins           |9      |9       |9       |\n",
      "|006092988X|A Tree Grows in Brooklyn                                     |Betty Smith     |1998               |Perennial               |9      |9       |9       |\n",
      "+----------+-------------------------------------------------------------+----------------+-------------------+------------------------+-------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def is_missing_or_unknown(col):\n",
    "    return (\n",
    "        F.col(col).isNull() |\n",
    "        (F.trim(F.col(col)) == \"\") |\n",
    "        (F.lower(F.trim(F.col(col))).isin(\"unknown\", \"n/a\", \"na\", \"null\"))\n",
    "    )\n",
    "\n",
    "# Clean book_title and book_author\n",
    "books_clean = books_before_cleaning \\\n",
    "    .withColumn(\n",
    "        \"book_title\",\n",
    "        F.when(is_missing_or_unknown(\"book_title\"),\n",
    "               F.lit(\"Unknown Title\"))\n",
    "         .otherwise(F.trim(F.col(\"book_title\")))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"book_author\",\n",
    "        F.when(is_missing_or_unknown(\"book_author\"),\n",
    "               F.lit(\"Unknown Author\"))\n",
    "         .otherwise(F.trim(F.col(\"book_author\")))\n",
    "    )\n",
    "\n",
    "# Clean year_of_publication\n",
    "year_str = F.trim(F.col(\"year_of_publication\").cast(\"string\"))\n",
    "\n",
    "books_clean = books_clean.withColumn(\n",
    "    \"year_of_publication\",\n",
    "    F.when(\n",
    "        year_str.rlike(r\"^[0-9]{4}$\"),         # 形如 1999 / 2005\n",
    "        year_str.cast(\"int\")\n",
    "    ).otherwise(F.lit(None).cast(\"int\"))       # 其它乱七八糟的直接当缺失\n",
    ")\n",
    "\n",
    "# Clean publisher\n",
    "books_clean = books_clean.withColumn(\n",
    "    \"publisher\",\n",
    "    F.when(is_missing_or_unknown(\"publisher\"),\n",
    "           F.lit(\"Unknown Publisher\"))\n",
    "     .otherwise(F.trim(F.col(\"publisher\")))\n",
    ")\n",
    "\n",
    "# Clean Summary\n",
    "books_clean = books_clean.withColumn(\n",
    "    \"Summary\",\n",
    "    F.when(is_missing_or_unknown(\"Summary\"),\n",
    "           F.lit(\"No Summary\"))\n",
    "     .otherwise(F.trim(F.col(\"Summary\")))\n",
    ")\n",
    "\n",
    "# Clean Language\n",
    "books_clean = books_clean.withColumn(\n",
    "    \"Language\",\n",
    "    F.when(is_missing_or_unknown(\"Language\"),\n",
    "           F.lit(\"Unknown Language\"))\n",
    "     .otherwise(F.lower(F.trim(F.col(\"Language\"))))\n",
    ")\n",
    "\n",
    "# Clean Category\n",
    "books_clean = books_clean.withColumn(\n",
    "    \"Category\",\n",
    "    F.when(is_missing_or_unknown(\"Category\"),\n",
    "           F.lit(\"Unknown Category\"))\n",
    "     .otherwise(F.trim(F.col(\"Category\")))\n",
    ")\n",
    "\n",
    "print(\"Final books_clean rows:\", books_clean.count())\n",
    "books_clean.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05390334",
   "metadata": {},
   "source": [
    "11. Consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f708ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ratings_clean rows: 65192\n",
      "Final distinct users: 3880\n",
      "Final distinct books: 1218\n",
      "Distinct isbn in ratings_clean: 1218\n",
      "Distinct isbn in books_clean: 1218\n"
     ]
    }
   ],
   "source": [
    "print(\"Final ratings_clean rows:\", ratings_clean.count())\n",
    "print(\"Final distinct users:\", ratings_clean.select(\"user_id\").distinct().count())\n",
    "print(\"Final distinct books:\", ratings_clean.select(\"isbn\").distinct().count())\n",
    "\n",
    "num_isbn_ratings = ratings_clean.select(\"isbn\").distinct().count()\n",
    "num_isbn_books = books_clean.select(\"isbn\").distinct().count()\n",
    "print(\"Distinct isbn in ratings_clean:\", num_isbn_ratings)\n",
    "print(\"Distinct isbn in books_clean:\", num_isbn_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534c116",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
